# Data Pipeline POC - BCEAO

[![Apache Iceberg](https://img.shields.io/badge/Apache%20Iceberg-1.8-blue.svg)](https://iceberg.apache.org/)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.5-orange.svg)](https://spark.apache.org/)
[![dbt](https://img.shields.io/badge/dbt-1.9-red.svg)](https://www.getdbt.com/)
[![MinIO](https://img.shields.io/badge/MinIO-S3%20Compatible-red.svg)](https://min.io/)
[![Airbyte](https://img.shields.io/badge/Airbyte-Integrated-purple.svg)](https://airbyte.com/)

A modern **Data Lakehouse** implementation using the **Medallion Architecture** (Bronze, Silver, Gold) with Apache Iceberg, Spark, dbt, and Airbyte for UEMOA economic indicators.

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| **[README.md](./README.md)** (this file) | Vue d'ensemble du projet, architecture et setup rapide |
| **[QUICK_REFERENCE.md](./QUICK_REFERENCE.md)** âš¡ | Guide de rÃ©fÃ©rence rapide - Commandes essentielles |
| **[DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md)** ğŸš€ | Guide de dÃ©ploiement complet Ã©tape par Ã©tape |
| **[ARCHITECTURE.md](./ARCHITECTURE.md)** ğŸ—ï¸ | Documentation technique approfondie |
| **[CONTRIBUTING.md](./CONTRIBUTING.md)** ğŸ¤ | Guide de contribution pour dÃ©veloppeurs |
| **[CHANGELOG.md](./CHANGELOG.md)** ğŸ“ | Historique des versions et modifications |
| **[QUICKSTART_FR.md](./QUICKSTART_FR.md)** ğŸ‡«ğŸ‡· | DÃ©marrage rapide en franÃ§ais |
| **[TRANSFORMATION_GUIDE_FR.md](./TRANSFORMATION_GUIDE_FR.md)** | Guide des transformations dbt |
| **[AIRBYTE_MINIO_INTEGRATION.md](./AIRBYTE_MINIO_INTEGRATION.md)** | Configuration Airbyte â†’ MinIO |
| **[MINIO_STRUCTURE_GUIDE.md](./MINIO_STRUCTURE_GUIDE.md)** | Structure des buckets MinIO |

[ğŸ‡«ğŸ‡· Version FranÃ§aise](./README_FR.md) | [âš¡ Quick Start](./QUICKSTART_FR.md)

## ğŸ—ï¸ Architecture Overview

This project implements a complete data pipeline for UEMOA (West African Economic and Monetary Union) economic indicators with:

- **Data Ingestion**: Airbyte (extracting data from sources)
- **Storage Layer**: MinIO (S3-compatible object storage)
- **Table Format**: Apache Iceberg (ACID transactions, time travel, schema evolution)
- **Processing Engine**: Apache Spark 3.5 with Iceberg support
- **Transformation Orchestration**: dbt 1.9 (Data Build Tool)
- **Serving Layers**: TimescaleDB (time-series), ChromaDB (vector database)

### Medallion Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INGESTION LAYER                            â”‚
â”‚                      (Airbyte)                                â”‚
â”‚          Extracting UEMOA Economic Indicators                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼ (Parquet files with Snappy compression)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BRONZE LAYER                               â”‚
â”‚     (Raw Data - indicateurs_economiques_uemoa)                â”‚
â”‚                   Storage: MinIO (S3)                         â”‚
â”‚      Format: Iceberg tables from Parquet files                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚  Transformation (dbt / Spark)
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SILVER LAYER                               â”‚
â”‚         (Cleaned Data - dim_uemoa_indicators)                 â”‚
â”‚     Cleaning, Validation, Type Casting, Calculations          â”‚
â”‚                   Format: Apache Iceberg                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚  Aggregation & Business Logic
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GOLD LAYER                                 â”‚
â”‚           (Analytics-Ready Data Marts)                        â”‚
â”‚  â€¢ gold_kpi_uemoa_growth_yoy                                  â”‚
â”‚  â€¢ gold_mart_uemoa_external_stability                         â”‚
â”‚  â€¢ gold_mart_uemoa_external_trade                             â”‚
â”‚  â€¢ gold_mart_uemoa_monetary_dashboard                         â”‚
â”‚  â€¢ gold_mart_uemoa_public_finance                             â”‚
â”‚                   Format: Apache Iceberg                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CONSUMPTION LAYERS                            â”‚
â”‚    â€¢ TimescaleDB (Time Series Analytics)                     â”‚
â”‚    â€¢ ChromaDB (Vector Search for AI/ML)                      â”‚
â”‚    â€¢ Jupyter Notebooks (Ad-hoc Analysis)                     â”‚
â”‚    â€¢ BI Dashboards (Tableau, Power BI, etc.)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Docker Desktop (with at least 8GB RAM)
- Docker Compose
- Available ports: 4040, 8888, 9000, 9001, 8181, 10000, 5433, 8010

### 1. Create `.env` file

```env
# Airbyte configuration
AIRBYTE_VERSION=0.50.44

# MinIO credentials (used by MinIO, Spark, and mc)
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=SuperSecret123

# TimescaleDB/Postgres credentials
POSTGRES_DB=monetary_policy_dm
POSTGRES_USER=postgres
POSTGRES_PASSWORD=PostgresPass123
```

### 2. Prepare AWS SDK JARs

Download the following JARs and place them in the `jars/` directory:

```bash
# Create jars directory
mkdir jars

# Download required JARs
# 1. hadoop-aws-3.3.4.jar
# Download from: https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar

# 2. aws-java-sdk-bundle-1.12.262.jar
# Download from: https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar
```

### 3. Start the services

```bash
# Build images (first time only)
docker-compose build

# Start all services
docker-compose up -d

# Check status
docker-compose ps
```

### 4. Verify installation

- **MinIO Console**: http://localhost:9001 (Login: admin / SuperSecret123)
- **Jupyter Notebook**: http://localhost:8888 (No password required)
- **Spark UI**: http://localhost:4040
- **Iceberg REST Catalog**: http://localhost:8181

### 5. Initialize Bronze layer (if using Airbyte)

If you're using Airbyte to ingest UEMOA economic indicators:

1. Configure Airbyte to output Parquet files with Snappy compression to `s3a://lakehouse/bronze/indicateurs_economiques_uemoa/`
2. After Airbyte sync, create the Iceberg table from Parquet files:

```bash
# Copy the creation script to the container
docker cp create_uemoa_table.py spark-iceberg:/tmp/

# Run the script to create the Bronze Iceberg table
docker exec spark-iceberg bash -lc "cd /opt/spark && ./bin/spark-submit \
  --jars /opt/spark/extra-jars/hadoop-aws-3.3.4.jar,/opt/spark/extra-jars/aws-java-sdk-bundle-1.12.262.jar \
  /tmp/create_uemoa_table.py"
```

### 6. Run dbt transformations

```bash
# Execute all transformations (Bronze â†’ Silver â†’ Gold)
docker exec dbt bash -c "cd /usr/app/dbt && dbt run"

# Run tests to validate data quality
docker exec dbt bash -c "cd /usr/app/dbt && dbt test"
```

## ğŸ“Š Components

| Service | Port | Description |
|---------|------|-------------|
| **MinIO** | 9000, 9001 | S3-compatible object storage |
| **Iceberg REST** | 8181 | Iceberg catalog service |
| **Spark/Jupyter** | 8888, 4040, 10000 | Processing engine & notebooks |
| **dbt** | - | Transformation orchestration |
| **TimescaleDB** | 5433 | Time-series database |
| **ChromaDB** | 8010 | Vector database |

## ğŸ“ Project Structure

```
data-pipeline-poc/
â”œâ”€â”€ docker-compose.yml          # Service orchestration
â”œâ”€â”€ spark.Dockerfile            # Custom Spark image with Iceberg
â”œâ”€â”€ spark-defaults.conf         # Spark configuration (S3 access, Iceberg)
â”œâ”€â”€ .env                        # Environment variables (credentials)
â”œâ”€â”€ jars/                       # AWS SDK JARs for S3 access
â”‚   â”œâ”€â”€ hadoop-aws-3.3.4.jar
â”‚   â””â”€â”€ aws-java-sdk-bundle-1.12.262.jar
â”œâ”€â”€ init-scripts/
â”‚   â””â”€â”€ init-lakehouse.sh      # Auto-initialization script
â”œâ”€â”€ dbt_project/               # dbt transformation project
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/           # Bronze â†’ Silver transformations
â”‚   â”‚   â”‚   â””â”€â”€ silver/
â”‚   â”‚   â”‚       â””â”€â”€ dim_uemoa_indicators.sql
â”‚   â”‚   â””â”€â”€ gold/              # Silver â†’ Gold transformations
â”‚   â”‚       â”œâ”€â”€ gold_kpi_uemoa_growth_yoy.sql
â”‚   â”‚       â”œâ”€â”€ gold_mart_uemoa_external_stability.sql
â”‚   â”‚       â”œâ”€â”€ gold_mart_uemoa_external_trade.sql
â”‚   â”‚       â”œâ”€â”€ gold_mart_uemoa_monetary_dashboard.sql
â”‚   â”‚       â””â”€â”€ gold_mart_uemoa_public_finance.sql
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â””â”€â”€ profiles.yml
â”œâ”€â”€ create_uemoa_table.py      # Script to create Bronze Iceberg table
â””â”€â”€ minio_data/                # MinIO storage (auto-created)
    â””â”€â”€ lakehouse/
        â”œâ”€â”€ bronze/            # Raw data from Airbyte (Parquet)
        â”‚   â””â”€â”€ indicateurs_economiques_uemoa/
        â”œâ”€â”€ silver/            # Cleaned data (Iceberg)
        â””â”€â”€ gold/              # Analytics-ready data (Iceberg)
```

## ğŸ”„ Data Flow

### Bronze Layer (Raw Data from Airbyte)
- **Source**: Airbyte extracting UEMOA economic indicators
- **Storage**: MinIO `s3a://lakehouse/bronze/indicateurs_economiques_uemoa/`
- **Format**: Parquet files with Snappy compression
- **Table**: `bronze.indicateurs_economiques_uemoa` (Iceberg table created from Parquet)
- **Purpose**: Store raw data immutably with Airbyte metadata
- **Features**: Append-only, timestamped, includes `_airbyte_*` columns

### Silver Layer (Cleaned & Validated Data)
- **Table**: `default_silver.dim_uemoa_indicators`
- **Source**: Bronze Iceberg table
- **Transformations**:
  - Remove Airbyte metadata columns
  - Cast data types appropriately
  - Calculate derived metrics (GDP ratios, balances, etc.)
  - Validate and clean null values
- **Purpose**: Provide clean, standardized dimension table

### Gold Layer (Analytics-Ready Data Marts)
- **Tables**:
  - `gold_kpi_uemoa_growth_yoy`: Year-over-year growth indicators
  - `gold_mart_uemoa_external_stability`: External trade and stability metrics
  - `gold_mart_uemoa_external_trade`: Trade balance and openness indicators
  - `gold_mart_uemoa_monetary_dashboard`: Monetary policy indicators
  - `gold_mart_uemoa_public_finance`: Public finance and debt metrics
- **Purpose**: Optimized tables for specific analytical use cases
- **Transformations**: Business logic, aggregations, KPI calculations

## ğŸ› ï¸ Common Commands

### Service Management

```bash
# Start services
docker-compose up -d

# Stop services
docker-compose down

# View logs
docker-compose logs -f spark-iceberg

# Restart a service
docker-compose restart spark-iceberg
```

### dbt Commands

```bash
# Run all models (Bronze â†’ Silver â†’ Gold)
docker exec dbt bash -c "cd /usr/app/dbt && dbt run"

# Run specific layer
docker exec dbt bash -c "cd /usr/app/dbt && dbt run --select staging"
docker exec dbt bash -c "cd /usr/app/dbt && dbt run --select gold"

# Run specific model
docker exec dbt bash -c "cd /usr/app/dbt && dbt run --select dim_uemoa_indicators"

# Test data quality
docker exec dbt bash -c "cd /usr/app/dbt && dbt test"

# Generate and serve documentation
docker exec dbt bash -c "cd /usr/app/dbt && dbt docs generate"
docker exec dbt bash -c "cd /usr/app/dbt && dbt docs serve --port 8080"
```

### Spark/Iceberg Commands

```bash
# Connect via Beeline (Spark Thrift Server)
docker exec -it spark-iceberg beeline -u jdbc:hive2://localhost:10000

# Execute a query
docker exec spark-iceberg beeline -u jdbc:hive2://localhost:10000 \
  -e "SELECT * FROM bronze.indicateurs_economiques_uemoa LIMIT 10;"

# Show all tables
docker exec spark-iceberg beeline -u jdbc:hive2://localhost:10000 \
  -e "SHOW TABLES IN bronze;"

# Describe table structure
docker exec spark-iceberg beeline -u jdbc:hive2://localhost:10000 \
  -e "DESCRIBE EXTENDED bronze.indicateurs_economiques_uemoa;"

# Create Bronze table from Airbyte Parquet files
docker exec spark-iceberg bash -lc "cd /opt/spark && ./bin/spark-submit \
  --jars /opt/spark/extra-jars/hadoop-aws-3.3.4.jar,/opt/spark/extra-jars/aws-java-sdk-bundle-1.12.262.jar \
  /tmp/create_uemoa_table.py"
```

### MinIO Commands

```bash
# List buckets
docker exec mc mc ls bceao-data/

# List files in bronze layer
docker exec mc mc ls bceao-data/lakehouse/bronze/indicateurs_economiques_uemoa/

# Copy file from MinIO
docker exec mc mc cp bceao-data/lakehouse/bronze/indicateurs_economiques_uemoa/file.parquet /tmp/

# View bucket statistics
docker exec mc mc du bceao-data/lakehouse
```

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. Airbyte Parquet files not accessible

**Problem**: `AccessDeniedException` when trying to read Parquet files from MinIO.

**Solution**: Ensure MinIO credentials are correctly set in `.env` and the Spark session has them configured:

```python
# In your PySpark script
spark = SparkSession.builder \
    .config("spark.hadoop.fs.s3a.access.key", "admin") \
    .config("spark.hadoop.fs.s3a.secret.key", "SuperSecret123") \
    .config("spark.hadoop.fs.s3a.endpoint", "http://minio:9000") \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .getOrCreate()
```

#### 2. AWS SDK Classes Not Found

**Problem**: `java.lang.NoClassDefFoundError: com/amazonaws/AmazonClientException`

**Solution**: Ensure the JARs are in the `jars/` directory and mounted correctly:
- Check `docker-compose.yml` has `- ./jars:/opt/spark/extra-jars`
- Verify JARs are present: `ls jars/`
- Include JARs when running Spark jobs: `--jars /opt/spark/extra-jars/hadoop-aws-3.3.4.jar,/opt/spark/extra-jars/aws-java-sdk-bundle-1.12.262.jar`

#### 3. dbt Model Fails with Column Not Found

**Problem**: Model references column that doesn't exist in source data.

**Solution**: 
1. Check available columns: `DESCRIBE EXTENDED bronze.indicateurs_economiques_uemoa`
2. Update model to use available columns
3. Verify Airbyte sync includes all expected fields

#### 4. Port Already in Use

**Problem**: `Bind for 0.0.0.0:9000 failed: port is already allocated`

**Solution**:
```bash
# Stop all containers
docker-compose down

# Check what's using the port
netstat -ano | findstr :9000  # Windows
lsof -i :9000                 # macOS/Linux

# Kill the process or change port in docker-compose.yml
```

## ğŸ“ˆ Data Models

### UEMOA Economic Indicators

The pipeline processes the following UEMOA economic indicators:

**Macroeconomic Indicators:**
- GDP (nominal, real growth rate)
- Sectoral weights (primary, secondary, tertiary)
- Inflation rate (average annual CPI)

**Public Finance:**
- Fiscal revenues (total and % of GDP)
- Total expenditures and net lending
- Budget balances (with/without grants)
- Public debt (stock and % of GDP)

**External Trade:**
- Exports (FOB)
- Imports (FOB)
- Trade balance
- Current account balance
- Trade openness degree

**Monetary Indicators:**
- Broad money (M2)
- Monetary emission coverage rate

All indicators are stored at the date level and transformed through the medallion architecture for different analytical purposes.

## ğŸ“– Documentation

### Quick Access

- [ğŸ“‹ Documentation Index](./DOCUMENTATION_INDEX.md) - Complete documentation map
- [ğŸ¯ Project Overview](./OVERVIEW.md) - Quick visual summary
- [âš¡ Quick Start Guide](./QUICKSTART_FR.md) - Get started in 15 minutes (FR)
- [ğŸ”„ Transformation Guide](./TRANSFORMATION_GUIDE_FR.md) - Data transformations (FR)
- [ğŸ“¦ MinIO Structure Guide](./MINIO_STRUCTURE_GUIDE.md) - Organize your data
- [âœ… Verification Report](./VERIFICATION_REPORT.md) - System status check
- [ğŸ“ Changelog](./CHANGELOG.md) - Version history
- [ğŸ“‹ Version Info](./VERSION_INFO.md) - Detailed version information

### Comprehensive Documentation (French)

For the complete technical documentation in French, see:
- **[README_FR.md](./README_FR.md)** - Complete architecture and setup guide

### Transformation Guides

- [ğŸ¦ UEMOA Data Transformations](./UEMOA_TRANSFORMATION_GUIDE_FR.md) - Economic indicators (FR) â­ **New**

### Integration Guides

- [ğŸ”— Airbyte-MinIO Integration](./AIRBYTE_MINIO_INTEGRATION.md) - Connect Airbyte to this pipeline

## ğŸ§ª Technologies

- **Apache Iceberg**: Open table format for huge analytic datasets
- **Apache Spark 3.5**: Unified analytics engine
- **dbt**: SQL-based transformation framework
- **MinIO**: High-performance S3-compatible object storage
- **TimescaleDB**: PostgreSQL extension for time-series data
- **ChromaDB**: AI-native open-source vector database

## ğŸ“ License

This project is developed as a proof of concept for BCEAO (Central Bank of West African States).

## ğŸ‘¥ Support

For questions or issues, please refer to the comprehensive French documentation in [README_FR.md](./README_FR.md).
